@misc{redmon2016lookonceunifiedrealtime,
  title         = {You Only Look Once: Unified, Real-Time Object Detection},
  author        = {Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
  year          = {2016},
  eprint        = {1506.02640},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1506.02640}
}

@inproceedings{8100173,
  author    = {Redmon, Joseph and Farhadi, Ali},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition
               (CVPR)},
  title     = {YOLO9000: Better, Faster, Stronger},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {6517-6525},
  keywords  = {Image resolution;Feature extraction;Training;Real-time
               systems;Object detection;Detectors},
  doi       = {10.1109/CVPR.2017.690}
}

@article{redmon2018yolov3,
  title   = {YOLOv3: An incremental improvement},
  author  = {Redmon, Joseph and Farhadi, Ali},
  journal = {arXiv preprint arXiv:1804.02767},
  year    = {2018}
}

@article{bochkovskiy2020yolov4,
  title   = {YOLOv4: Optimal speed and accuracy of object detection},
  author  = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal = {arXiv preprint arXiv:2004.10934},
  year    = {2020}
}

@article{8627998,
  author   = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Object Detection With Deep Learning: A Review},
  year     = {2019},
  volume   = {30},
  number   = {11},
  pages    = {3212-3232},
  keywords = {Object detection;Deep learning;Task analysis;Feature
              extraction;Computer architecture;Training;Neural networks;Deep
              learning;neural network;object detection},
  doi      = {10.1109/TNNLS.2018.2876865}
}

@misc{liu2019deeplearninggenericobject,
  title         = {Deep Learning for Generic Object Detection: A Survey},
  author        = {Li Liu and Wanli Ouyang and Xiaogang Wang and Paul Fieguth and Jie
                   Chen and Xinwang Liu and Matti Pietikäinen},
  year          = {2019},
  eprint        = {1809.02165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1809.02165}
}

@inproceedings{7410526,
  author    = {Girshick, Ross},
  booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
  title     = {Fast R-CNN},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {1440-1448},
  keywords  = {Training;Proposals;Feature extraction;Object
               detection;Pipelines;Computer architecture;Open source software},
  doi       = {10.1109/ICCV.2015.169}
}

@inbook{Chan2020,
  author    = {Chan, Heang-Ping and Samala, Ravi K. and Hadjiiski, Lubomir M. and
               Zhou, Chuan},
  editor    = {Lee, Gobert and Fujita, Hiroshi},
  title     = {Deep Learning in Medical Image Analysis},
  booktitle = {Deep Learning in Medical Image Analysis : Challenges and
               Applications},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {3--21},
  abstract  = {Deep learning is the state-of-the-art machine learning approach.
               The success of deep learning in many pattern recognition
               applications has brought excitement and high expectations that deep
               learning, or artificial intelligence (AI), can bring revolutionary
               changes in health care. Early studies of deep learning applied to
               lesion detection or classification have reported superior
               performance compared to those by conventional techniques or even
               better than radiologists in some tasks. The potential of applying
               deep-learning-based medical image analysis to computer-aided
               diagnosis (CAD), thus providing decision support to clinicians and
               improving the accuracy and efficiency of various diagnostic and
               treatment processes, has spurred new research and development
               efforts in CAD. Despite the optimism in this new era of machine
               learning, the development and implementation of CAD or AI tools in
               clinical practice face many challenges. In this chapter, we will
               discuss some of these issues and efforts needed to develop robust
               deep-learning-based CAD tools and integrate these tools into the
               clinical workflow, thereby advancing towards the goal of providing
               reliable intelligent aids for patient care.},
  isbn      = {978-3-030-33128-3},
  doi       = {10.1007/978-3-030-33128-3_1},
  url       = {https://doi.org/10.1007/978-3-030-33128-3_1}
}

@article{Koirala2019,
  author   = {Koirala, A. and Walsh, K. B. and Wang, Z. and McCarthy, C.},
  title    = {Deep learning for real-time fruit detection and orchard fruit load
              estimation: benchmarking of 'MangoYOLO'},
  journal  = {Precision Agriculture},
  year     = {2019},
  month    = {12},
  volume   = {20},
  number   = {6},
  pages    = {1107--1135},
  doi      = {10.1007/s11119-019-09642-0},
  url      = {https://doi.org/10.1007/s11119-019-09642-0},
  issn     = {1573-1618},
  abstract = {The performance of six existing deep learning architectures were
              compared for the task of detection of mango fruit in images of tree
              canopies. Images of trees (n = 1 515) from across five orchards
              were acquired at night using a 5 Mega-pixel RGB digital camera and
              720 W of LED flood lighting in a rig mounted on a farm utility
              vehicle operating at 6 km/h. The two stage deep learning
              architectures of Faster R-CNN(VGG) and Faster R-CNN(ZF), and the
              single stage techniques YOLOv3, YOLOv2, YOLOv2(tiny) and SSD were
              trained both with original resolution and 512 × 512 pixel versions
              of 1 300 training tiles, while YOLOv3 was run only with 512 × 512
              pixel images, giving a total of eleven models. A new architecture
              was also developed, based on features of YOLOv3 and YOLOv2(tiny),
              on the design criteria of accuracy and speed for the current
              application. This architecture, termed 'MangoYOLO', was trained
              using: (i) the 1 300 tile training set, (ii) the COCO dataset
              before training on the mango training set, and (iii) a daytime
              image training set of a previous publication, to create the
              MangoYOLO models 's', 'pt' and 'bu', respectively. Average
              Precision plateaued with use of around 400 training tiles.
              MangoYOLO(pt) achieved a F1 score of 0.968 and Average Precision of
              0.983 on a test set independent of the training set, outperforming
              other algorithms, with a detection speed of 8 ms per 512 × 512
              pixel image tile while using just 833 Mb GPU memory per image (on a
              NVIDIA GeForce GTX 1070 Ti GPU) used for in-field application. The
              MangoYOLO model also outperformed other models in processing of
              full images, requiring just 70 ms per image (2 048 × 2 048 pixels)
              (i.e., capable of processing ~ 14 fps) with use of 4 417 Mb of GPU
              memory. The model was robust in use with images of other orchards,
              cultivars and lighting conditions. MangoYOLO(bu) achieved a F1
              score of 0.89 on a day-time mango image dataset. With use of a
              correction factor estimated from the ratio of human count of fruit
              in images of the two sides of sample trees per orchard and a hand
              harvest count of all fruit on those trees, MangoYOLO(pt) achieved
              orchard fruit load estimates of between 4.6 and 15.2% of packhouse
              fruit counts for the five orchards considered. The labelled images
              (1 300 training, 130 validation and 300 test) of this study are
              available for comparative studies.}
}

@article{electronics8030292,
  author         = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Chris and
                    Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and
                    Hasan, Mahmudul and Van Essen, Brian C. and Awwal, Abdul A. S. and
                    Asari, Vijayan K.},
  title          = {A State-of-the-Art Survey on Deep Learning Theory and Architectures},
  journal        = {Electronics},
  volume         = {8},
  year           = {2019},
  number         = {3},
  article-number = {292},
  url            = {https://www.mdpi.com/2079-9292/8/3/292},
  issn           = {2079-9292},
  abstract       = {In recent years, deep learning has garnered tremendous success in
                    a variety of application domains. This new field of machine
                    learning has been growing rapidly and has been applied to most
                    traditional application domains, as well as some new areas that
                    present more opportunities. Different methods have been proposed
                    based on different categories of learning, including supervised,
                    semi-supervised, and un-supervised learning. Experimental results
                    show state-of-the-art performance using deep learning when compared
                    to traditional machine learning approaches in the fields of image
                    processing, computer vision, speech recognition, machine
                    translation, art, medical imaging, medical information processing,
                    robotics and control, bioinformatics, natural language processing,
                    cybersecurity, and many others. This survey presents a brief survey
                    on the advances that have occurred in the area of Deep Learning
                    (DL), starting with the Deep Neural Network (DNN). The survey goes
                    on to cover Convolutional Neural Network (CNN), Recurrent Neural
                    Network (RNN), including Long Short-Term Memory (LSTM) and Gated
                    Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN)
                    , Generative Adversarial Network (GAN), and Deep Reinforcement
                    Learning (DRL). Additionally, we have discussed recent developments
                    , such as advanced variant DL techniques based on these DL
                    approaches. This work considers most of the papers published after
                    2012 from when the history of deep learning began. Furthermore, DL
                    approaches that have been explored and evaluated in different
                    application domains are also included in this survey. We also
                    included recently developed frameworks, SDKs, and benchmark
                    datasets that are used for implementing and evaluating deep
                    learning approaches. There are some surveys that have been
                    published on DL using neural networks and a survey on Reinforcement
                    Learning (RL). However, those papers have not discussed individual
                    advanced techniques for training large-scale deep learning models
                    and the recently developed method of generative models.},
  doi            = {10.3390/electronics8030292}
}

@article{KAMILARIS201870,
  title    = {Deep learning in agriculture: A survey},
  journal  = {Computers and Electronics in Agriculture},
  volume   = {147},
  pages    = {70-90},
  year     = {2018},
  issn     = {0168-1699},
  doi      = {https://doi.org/10.1016/j.compag.2018.02.016},
  url      = {https://www.sciencedirect.com/science/article/pii/S0168169917308803},
  author   = {Andreas Kamilaris and Francesc X. Prenafeta-Boldú},
  keywords = {Deep learning, Agriculture, Survey, Convolutional Neural Networks,
              Recurrent Neural Networks, Smart farming, Food systems},
  abstract = {Deep learning constitutes a recent, modern technique for image
              processing and data analysis, with promising results and large
              potential. As deep learning has been successfully applied in
              various domains, it has recently entered also the domain of
              agriculture. In this paper, we perform a survey of 40 research
              efforts that employ deep learning techniques, applied to various
              agricultural and food production challenges. We examine the
              particular agricultural problems under study, the specific models
              and frameworks employed, the sources, nature and pre-processing of
              data used, and the overall performance achieved according to the
              metrics used at each work under study. Moreover, we study
              comparisons of deep learning with other existing popular techniques
              , in respect to differences in classification or regression
              performance. Our findings indicate that deep learning provides high
              accuracy, outperforming existing commonly used image processing
              techniques.}
}

@misc{Raikokte2020,
  author       = {Raikokte, Pranav},
  title        = {COVID-19 Image Dataset},
  year         = {2020},
  howpublished = {Kaggle},
  url          = {https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset},
  note         = {Accessed: 2024-04-11}
}

@misc{Wallington2023,
  author       = {Wallington, Graham},
  title        = {The Evolution of YOLO: Joseph Redmon's Departure and the Ethics of Computer Vision},
  year         = {2023},
  howpublished = {Medium},
  url          = {https://medium.com/@graham.wallington/the-evolution-of-yolo-joseph-redmons-departure-and-the-ethics-of-computer-vision-66d9b75f0eca},
  note         = {Accessed: 2024-04-11}
}

@misc{Ultralytics2024,
  author       = {Ultralytics},
  title        = {Models Documentation},
  year         = {2024},
  howpublished = {Ultralytics Documentation},
  url          = {https://docs.ultralytics.com/models/},
  note         = {Accessed: 2024-04-11}
}

@misc{V7Labs2024,
  author       = {V7 Labs},
  title        = {YOLO Object Detection Explained},
  year         = {2024},
  howpublished = {V7 Labs Blog},
  url          = {https://www.v7labs.com/blog/yolo-object-detection},
  note         = {Accessed: 2024-04-11}
}

@misc{PapersWithCode2024,
  author       = {Papers With Code},
  title        = {Real-Time Object Detection},
  year         = {2024},
  howpublished = {Papers With Code},
  url          = {https://paperswithcode.com/task/real-time-object-detection},
  note         = {Accessed: 2024-04-11}
}

@misc{Zhou2023,
  author       = {Zhou, Jeffrey},
  title        = {YOLO v1 Implementation},
  year         = {2023},
  howpublished = {GitHub},
  url          = {https://github.com/tanjeffreyz/yolo-v1},
  note         = {Accessed: 2024-04-11}
}

@misc{DataCamp2023,
  author       = {DataCamp},
  title        = {YOLO Object Detection Explained},
  year         = {2023},
  howpublished = {DataCamp Blog},
  url          = {https://www.datacamp.com/blog/yolo-object-detection-explained},
  note         = {Accessed: 2024-04-11}
}

@misc{Roboflow2023,
  author       = {Roboflow},
  title        = {What is an Anchor Box?},
  year         = {2023},
  howpublished = {Roboflow Blog},
  url          = {https://blog.roboflow.com/what-is-an-anchor-box/},
  note         = {Accessed: 2024-04-11}
}

@misc{Neuralception2023,
  author       = {Neuralception},
  title        = {Object Detection - YOLO},
  year         = {2023},
  howpublished = {Neuralception Blog},
  url          = {https://www.neuralception.com/objectdetection-yolo/},
  note         = {Accessed: 2024-04-11}
}

@misc{Rao2024,
  author       = {Rao, Nikhil},
  title        = {YOLOv11 Explained: Next Level Object Detection with Enhanced Speed and Accuracy},
  year         = {2024},
  howpublished = {Medium},
  url          = {https://medium.com/@nikhil-rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-accuracy-2dbe2d376f71},
  note         = {Accessed: 2024-04-11}
}

@misc{Roboflow2025,
  author       = {Roboflow},
  title        = {Use YOLOv12 with Roboflow},
  year         = {2025},
  howpublished = {Roboflow Blog},
  url          = {https://blog.roboflow.com/use-yolov12-with-roboflow/},
  note         = {Accessed: 2024-04-11}
}

@misc{VisoAI2024,
  author       = {VisoAI},
  title        = {YOLO Explained},
  year         = {2024},
  howpublished = {VisoAI Blog},
  url          = {https://viso.ai/computer-vision/yolo-explained/},
  note         = {Accessed: 2024-04-11}
}

@misc{IBM2024,
  author       = {IBM},
  title        = {Convolutional Neural Networks},
  year         = {2024},
  howpublished = {IBM Think},
  url          = {https://www.ibm.com/think/topics/convolutional-neural-networks},
  note         = {Accessed: 2024-04-11}
}

@inproceedings{ChanCell2020,
  author = {Chan, K. S. and Chen, H. S. and Liang, W. C.},
  title = {Cell Detection in Microscopy Images Using {YOLO}},
  booktitle = {2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year = {2020},
  pages = {3076--3081},
  publisher = {IEEE},
  doi = {10.1109/SMC42975.2020.9283456}
}